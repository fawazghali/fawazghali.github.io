Please email me at fawaz.ghali@hazelcast.com

Fawaz Ghali is a public speaker, author, and expert with 25+ years in DevX, DevRel, AI/ML, and Data Engineering. He holds a PhD in Computer Science, has published 45+ peer-reviewed papers, and delivered 200+ talks at global conferences.

Real-Time Insights at Scale: Microservices Architecture with Stream Processing
Real-time stream processing is growing exponentially in recent years, businesses need to gather insights from real-time data as soon as it’s generated. To do this, developers and software architects use various pipelines and tools to capture and process data in motion. Real-time stream processing has its own challenges such as testing and life-cycle management, scaling and performance, event time and late events, streaming fault tolerance, and processing guarantees. In this talk, I will address those challenges and demonstrate the best practices for real-time stream processing, from data ingestion to data processing with ultra-low latency at scale and at speed. I will discuss how you can optimize your real-time streaming projects in the following areas: scalability, performance, failover, reliability, and data recovery.


Unveiling the Invisible: Real-Time Anomaly Detection through AI
Logs and traces generated by applications are valuable sources of information that can help detect issues and improve performance. However, they are often treated separately from other data, even though they are no different from the data an application works with. In this talk, we will explore a different approach: treating logs and traces as part of a scalable cloud storage repository that can be analyzed with the same techniques used for big data. By keeping all the data together, we can apply machine learning models to detect situations of interest and alert us in real-time when unwanted behavior is occurring or brewing. This approach enables intelligent monitoring that goes beyond simple threshold-based alerts and can help identify complex issues that would otherwise go unnoticed. We will discuss how to harness existing technologies to implement this approach, providing attendees with practical tips and insights that they can apply to their own projects.

The Fraud Hunter's Playbook: Real-Time Detection Challenges and Tactics
Fraud can be considerably reduced via speed, scalability, and stability. Investigating fraudulent activities, using fraud detection machine learning is crucial where decisions need to be made in microseconds, not seconds or even milliseconds. This becomes more challenging when things get demanding and scaling real-time fraud detection becomes a bottleneck. The talk will address these challanges and provide solutions using a combination of real-time storage and computing that provides a unique synergy for real-time use cases at any scale.

Boosting Similarity Search With Real-time Stream Processing
The goal of similarity search and vector databases is to find similar results to the search query for unstructured data, such as text, images, and videos. The unstructured data first is vectorized, and stored in a vector format. There are publicly available tools to create vectors from unstructured data; similarly, there are vector databases to store and perform similarity searches. This is important because of the rising popularity of Large Language Models (LLMs) and their combination with vector databases. Here, we present a hybrid approach by taking the strengths of vector databases and boosting them with traditional search and filtering techniques based on real-time stream processing. Vector databases are good for building high-performance vector search applications. On the other hand, stream processing can be used for real-time fast data storage for structured data (filters, tags, and contextual data). In this work, we're adding context and memory to vector databases to ingest, enrich, predict, and act on your data in a simplified but efficient approach. In this talk, we’ll focus on how Real-time compute APIs help leverage the processing capabilities of a distributed cluster, so you aren’t leaving large potential performance gains on the table. The combination of Real-time storage and computing provides a unique synergy that enables applications to address real-time use cases at any scale.

Kafka's Next Frontier: Real-Time Contextual Data Enrichment
Developing high-performance large-stream processing applications is a challenging task. Choosing the right tool(s) is crucial to get the job done; as developers, we tend to focus on performance, simplicity, and cost. However, the cost becomes relatively high if we end up with two or more tools to do the same task. Simply put, you need to multiply development time, deployment time, and maintenance costs by the number of tools. Kafka is great for event streaming architectures, continuous data integration (ETL), and messaging systems of record (database). However, Kafka has some challenges, such as a complex architecture with many moving parts, it can’t be embedded, and it’s a centralized middleware, just like a database. Moreover, Kafka does not offer batch processing, and all intermediate steps are materialized to disk in Kafka. This leads to enormous disk space usage. In this talk, we will address these challenges and how real-time stream processing can be used to enhance Kafka pipelines by simplifying deployment and operations with ultra-low latency and a lightweight architecture making it a great tool for edge (restricted) environments. This talk aims to take your Kafka applications to the next level. The combination of Real-time storage and computing provides a unique synergy that enables applications to address real-time use cases at any scale.


Pizza Delivery in Motion: Real-time Pizza Delivery Service at Scale
Most of us love pizza, so let’s use a pizza delivery service as an example. Our pizza delivery service receives orders from multiple users in real time; but what if you want to recommend specific starters for specific types of pizzas and enrich pizza orders with contextual data? How can you do this in real time? In this talk, we will address real-time application challenges and how real-time stream processing can be used to enhance data streaming pipelines by simplifying deployment and operations with ultra-low latency. The combination of Real-time storage and computing provides a unique synergy that enables applications to address real-time use cases at any scale.


Building Event-Driven Microservices in Java
The microservices architecture, with its emphasis on independent services and teams, has been shown to offer many advantages in terms of agility and time to market. At the same time, as microservices proliferate, new challenges have arisen. Chains of synchronous calls can produce high latency and make it difficult to scale up. The event-driven microservices architecture addresses the new scaling challenges by introducing reliable asynchronous interactions. Shifting to an event-driven architecture also makes it easy to implement some important enterprise features like zero downtime service updates, canary deployments, and rate-limiting. This session will start with an architecture-level discussion of event-driven microservices and progress to implementation and best practices for Event-Driven Microservices.

Best Practices for Data Serialization in Event-Driven Microservices
This talk will cover the question of Which serialization option is best? The selection of serialization method directly impacts the dimensions of the data object. Prior to confirming the serialization choice, attempting to analyze the raw data to estimate memory requirements is merely a surface-level approach. Opting for one serialization method over another can significantly inflate the data size, sometimes by a factor of 10. In scenarios involving a substantial volume of such data, conducting benchmarks becomes crucial. This assessment helps determine whether the additional development efforts are justified for the sake of minimizing memory usage and transmission time. However, in cases where the dataset is limited, the memory overhead may not be a critical factor, and prioritizing development simplicity becomes more preferable. Additionally, the introduction of a near-cache can mitigate the relevance of network transmission costs.
